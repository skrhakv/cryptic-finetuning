{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import gettempdir\n",
    "from biotite.structure import get_residues, get_chains\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.database.rcsb as rcsb\n",
    "import biotite\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "shutil.rmtree('../data/apo-sequence-annotations/', ignore_errors=True)\n",
    "os.makedirs('../data/apo-sequence-annotations', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE APO SEQUENCES WITH ANNOTATIONS\n",
    "## CAUTION\n",
    "You need to add a library from a [separate project](https://github.com/skrhakv/deeplife-project/blob/master/src/deeplife_utils.py) (update the `sys.path.append(...)` path). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append('/home/vit/Projects/deeplife-project/src')\n",
    "import deeplife_utils\n",
    "\n",
    "CIF_FILES = '/home/vit/Projects/deeplife-project/data/cif_files'\n",
    "with open(f'../cryptobench-dataset/dataset.json', 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "for apo_structure, holo_structures in dataset.items():\n",
    "    \n",
    "    # print(f'Processing {apo_structure} ...')\n",
    "    binding_residues = set()\n",
    "    chain_id = holo_structures[0]['apo_chain']\n",
    "\n",
    "    # skip multichain structures\n",
    "    if '-' in chain_id:\n",
    "        continue\n",
    "    if os.path.isfile(f'../data/apo-sequence-annotations/{apo_structure.lower()}{chain_id.upper()}.txt'):\n",
    "        continue\n",
    "\n",
    "    for holo_structure in holo_structures:\n",
    "\n",
    "        apo_pocket = holo_structure['apo_pocket_selection']\n",
    "        \n",
    "        new_apo_residues = [residue.split(\n",
    "            '_')[1] for residue in apo_pocket]\n",
    "\n",
    "        binding_residues.update(new_apo_residues)\n",
    "\n",
    "    cif_file_path = rcsb.fetch(apo_structure, \"cif\", target_path=CIF_FILES)\n",
    "\n",
    "    cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "    auth = get_structure(cif_file, model=1)\n",
    "    auth = auth[\n",
    "            (auth.chain_id == chain_id) &\n",
    "            (biotite.structure.filter_peptide_backbone(auth))]\n",
    "    \n",
    "    # skip if no residues left\n",
    "    if len(auth) == 0: \n",
    "        print(f'No residues left for {apo_structure} {chain_id}')\n",
    "        continue\n",
    "\n",
    "    # filter to get correct chain; filter only for peptides\n",
    "    auth_residues_only = get_residues(auth)\n",
    "\n",
    "    zero_based_binding_residues = []\n",
    "    sequence = \"\"\n",
    "    # to handle cases where residue indices are named like this: 60A, 60B, 60C, ...\n",
    "    previous_seq_id = float('-inf')\n",
    "    letter_counter = 0\n",
    "    for idx, (auth_seq_id, resname) in enumerate(zip(auth_residues_only[0], auth_residues_only[1])):\n",
    "        if previous_seq_id == auth_seq_id:\n",
    "            letter_counter += 1\n",
    "        elif letter_counter > 0:\n",
    "            letter_counter = 0\n",
    "        one_letter_aa = deeplife_utils.three_to_one(resname)\n",
    "        if str(auth_seq_id) in binding_residues or (str(auth_seq_id) + chr(ord('A') + letter_counter)) in binding_residues:\n",
    "            zero_based_binding_residues.append(one_letter_aa + str(idx))\n",
    "        sequence += one_letter_aa\n",
    "        previous_seq_id = auth_seq_id\n",
    "\n",
    "    with open(f'../data/apo-sequence-annotations/{apo_structure.lower()}{chain_id.upper()}.txt', 'w') as f:\n",
    "        f.write(\n",
    "            f'{apo_structure};{chain_id};UNKNOWN;{\" \".join(zero_based_binding_residues)};{sequence}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "OUTPUT_PATH = '../data/sequences'\n",
    "INPUT_PATH = '../data/apo-sequence-annotations/'\n",
    "for file in os.listdir(INPUT_PATH):\n",
    "    with open(f'{INPUT_PATH}{file}', 'r') as f:\n",
    "        csv_reader = csv.reader(f, delimiter=';')\n",
    "        sequence = next(csv_reader)[4]\n",
    "    with open(f'{OUTPUT_PATH}/{file}', 'w') as f:\n",
    "        f.write(sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATE THREE TXT FILES\n",
    "1. `apo_test.txt`: containing the test set\n",
    "2. `apo_train.txt`: containing the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "DIR_PATH = '/home/skrhakv/deeplife/deeplife-project/'\n",
    "\n",
    "TEST_PATH = ['/home/vit/Projects/cryptic-nn/cryptobench-dataset/folds/test.json']\n",
    "TRAIN_PATH = ['/home/vit/Projects/cryptic-nn/cryptobench-dataset/folds/train-fold-0.json',\n",
    "              '/home/vit/Projects/cryptic-nn/cryptobench-dataset/folds/train-fold-1.json',\n",
    "              '/home/vit/Projects/cryptic-nn/cryptobench-dataset/folds/train-fold-2.json',\n",
    "              '/home/vit/Projects/cryptic-nn/cryptobench-dataset/folds/train-fold-3.json'\n",
    "              ]\n",
    "APO_ANNOTATIONS_PATH = '/home/vit/Projects/cryptic-nn/data/apo-sequence-annotations'\n",
    "OUTPUT_PATH = '/home/vit/Projects/cryptic-nn/data'\n",
    "\n",
    "def read_cryptobench_subset(subset_paths):\n",
    "    apo_subset = []\n",
    "    for file in subset_paths:\n",
    "        # load the CryptoBench subset from file\n",
    "        with open(file, 'r') as json_file:\n",
    "            dataset = json.load(json_file)\n",
    "\n",
    "        # read the JSON\n",
    "        for apo_pdb_id, holo_structures in dataset.items():\n",
    "\n",
    "            # find and read the apo file\n",
    "            apo_chain_id = holo_structures[0]['apo_chain']\n",
    "            apo_filename = f'{APO_ANNOTATIONS_PATH}/{apo_pdb_id}{apo_chain_id}.txt'\n",
    "            if os.path.isfile(apo_filename):\n",
    "                with open(apo_filename, 'r') as apo_file:\n",
    "                    apo_subset.extend(apo_file.readlines())\n",
    "    return apo_subset\n",
    "\n",
    "# extract the annotations\n",
    "train_apo = read_cryptobench_subset(TRAIN_PATH)\n",
    "test_apo = read_cryptobench_subset(TEST_PATH)\n",
    "\n",
    "# merge the annotations into a single file\n",
    "with open(f'{OUTPUT_PATH}/apo_test.txt', 'w') as apo_test_file:\n",
    "    apo_test_file.write('\\n'.join(test_apo))\n",
    "with open(f'{OUTPUT_PATH}/apo_train.txt', 'w') as apo_train_file:\n",
    "    apo_train_file.write('\\n'.join(train_apo))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
