{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b08f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 16:56:03.020: Failed to load module \"pk-gtk-module\"\n",
      "Cannot open file '/home/vit/Projects/cryptic-nn/src/prediction-analysis/data/pymol/icons/icon2.svg', because: No such file or directory\n",
      "Cannot open file '/home/vit/Projects/cryptic-nn/src/prediction-analysis/data/pymol/icons/icon2.svg', because: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not read PyMOL stylesheet.\n",
      "DEBUG: PYMOL_DATA='./data'\n",
      " Detected OpenGL version 4.6. Shaders available.\n",
      " Geometry shaders not available\n",
      " Detected GLSL version 4.60.\n",
      " Setting: fetch_path set to /home/vit/Projects/deeplife-project/data/cif_files.\n",
      " ExecutiveLoad-Detail: Detected mmCIF\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pymol\n",
    "_stdouterr = sys.stdout, sys.stderr\n",
    "pymol.finish_launching(['/usr/bin/pymol', '-q'])\n",
    "sys.stdout, sys.stderr = _stdouterr\n",
    "\n",
    "# load something into the PyMOL window\n",
    "from pymol import cmd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1846fa0b",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "Cluster the predictions into pockets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dad7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, AgglomerativeClustering\n",
    "\n",
    "EPSILON = 7  # Max distance for neighbors (adjust as needed)\n",
    "MIN_SAMPLES = 3  # Minimum points to form a cluster         (adjust as needed)\n",
    "\n",
    "def compute_clusters(points: list[list[float]], prediction_scores: list[float]):\n",
    "    # This function computes clusters for the given points and prediction scores\n",
    "    points_array = np.array(points)\n",
    "    scores_array = np.array(prediction_scores).reshape(-1, 1)\n",
    "    stacked = np.hstack((points_array, scores_array))  # Combine coordinates with scores\n",
    "\n",
    "    high_score_mask = stacked[:, 3] > 0.65  # TODO: tweak this\n",
    "    high_score_points = stacked[high_score_mask][:, :3]  # Extract only (x, y, z) coordinates\n",
    "\n",
    "    dbscan = DBSCAN(eps=EPSILON, min_samples=MIN_SAMPLES)\n",
    "    # dbscan = AgglomerativeClustering(distance_threshold=EPSILON, n_clusters=None, linkage='single')\n",
    "    labels = dbscan.fit_predict(high_score_points)\n",
    "\n",
    "    # Initialize all labels to -1\n",
    "    all_labels = -1 * np.ones(len(points), dtype=int)\n",
    "    # Assign cluster labels to high score points\n",
    "    all_labels[high_score_mask] = labels\n",
    "    labels = all_labels\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys, os\n",
    "import numpy as np\n",
    "\n",
    "from biotite.structure import get_residues, get_residue_starts\n",
    "from biotite.structure.io.pdbx import get_structure\n",
    "import biotite.structure.io.pdbx as pdbx\n",
    "import biotite.database.rcsb as rcsb\n",
    "import biotite\n",
    "\n",
    "\n",
    "DATASET = 'cryptobench'\n",
    "CIF_FILES = '/home/vit/Projects/deeplife-project/data/cif_files'\n",
    "PREDICTIONS_PATH = '/home/vit/Projects/cryptic-nn/data/predictions/ESM2-3B-extended-finetuning'\n",
    "COLORS = ['red', 'pink', 'purple', 'purpleblue', 'raspberry', 'ruby', 'salmon', 'sand', 'skyblue', 'slate', 'smudge', 'splitpea', 'sulfur', 'teal', 'tv_blue', 'tv_green', 'tv_orange', 'tv_red', 'tv_yellow']\n",
    "with open(f'../../datasets/{DATASET}-dataset/folds/test.json', 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "skip = False\n",
    "# skip = True\n",
    "\n",
    "for apo_structure, holo_structures in dataset.items():\n",
    "\n",
    "    # finished analysis at: '5wbmB' structure\n",
    "    if skip:\n",
    "        if apo_structure == '5wm9':\n",
    "            skip = False\n",
    "        else:\n",
    "            continue\n",
    "    chain_id = holo_structures[0]['apo_chain']\n",
    "\n",
    "    # skip multichain structures\n",
    "    if '-' in chain_id:\n",
    "        continue\n",
    "\n",
    "\n",
    "    cif_file_path = rcsb.fetch(apo_structure, \"cif\", target_path=CIF_FILES)\n",
    "\n",
    "    cif_file = pdbx.CIFFile.read(cif_file_path)\n",
    "\n",
    "    auth = get_structure(cif_file, model=1)\n",
    "    auth = auth[\n",
    "            (auth.chain_id == chain_id) &\n",
    "            (biotite.structure.filter_peptide_backbone(auth))]\n",
    "    \n",
    "    protein_id = f'{apo_structure}{chain_id}'\n",
    "    # skip if no residues left\n",
    "    if len(auth) == 0: \n",
    "        print(f'No residues left for {protein_id}')\n",
    "        continue\n",
    "\n",
    "    # filter to get correct chain; filter only for peptides\n",
    "    auth_residues_only = auth[get_residue_starts(auth)]\n",
    "\n",
    "    predictions = np.load(f'{PREDICTIONS_PATH}/predictions/{protein_id}.npy') > 0.5\n",
    "    \n",
    "    assert len(predictions) == len(auth_residues_only), f\"Length of auth residues and predictions do not match for {protein_id}: {len(auth_residues_only)} vs {len(predictions)}\"\n",
    "    predicted_binding_residues = auth_residues_only[predictions]\n",
    "    predicted_binding_residue_coords, predicted_binding_residue_auth_labels = predicted_binding_residues.coord, predicted_binding_residues.res_id\n",
    "\n",
    "    clusters = compute_clusters(predicted_binding_residue_coords, predictions[predictions])\n",
    "    \n",
    "    cmd.reinitialize()\n",
    "    cmd.set('fetch_path', cmd.exp_path(CIF_FILES), quiet=0)\n",
    "    cmd.fetch(protein_id)\n",
    "    cmd.zoom(protein_id)\n",
    "    cmd.color('grey', protein_id)\n",
    "\n",
    "    for i in range(-1, max(clusters) + 1):\n",
    "        cluster_residue_auth_labels = predicted_binding_residue_auth_labels[clusters == i]\n",
    "        if i == -1 and len(cluster_residue_auth_labels) == 0:\n",
    "            continue\n",
    "        cmd.color(COLORS[i + 1], f'{protein_id} and resi {\"+\".join([str(i) for i in cluster_residue_auth_labels])}')\n",
    "        \n",
    "    cmd.show('surface', protein_id)\n",
    "    input(\">Press Enter for the next protein...\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
